import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import os
import tensorflow as tf
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Load your data (update path accordingly)
data = pd.read_csv('/mnt/data/final_training_file.csv')  # Using the uploaded file path
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# Get a list of all unique states
states = data['State'].unique()

# Create a directory to save the models
if not os.path.exists('models'):
    os.makedirs('models')

# Function to create a dataset with look-back sequences
def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        X.append(dataset[i:(i + look_back), 0])
        Y.append(dataset[i + look_back, 0])  # Petroleum Consumption column
    return np.array(X), np.array(Y)

# Adjusted parameters
look_back = 12  # Increased look-back to capture more historical context
lstm_units = 100  # Adjust number of units in LSTM
batch_size = 16  # Increased batch size
epochs = 200  # Increased number of epochs for training

# Loop through each state and train the LSTM model
for state in states:
    print(f"Training LSTM model for state: {state}")
    
    # Extract data for the current state
    petroleum_sales = data[data['State'].str.lower() == state.lower()]['Petroleum_Consumption'].values.reshape(-1, 1)
    
    # Normalize the features
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_values = scaler.fit_transform(petroleum_sales)
    
    # Create datasets
    X, Y = create_dataset(scaled_values, look_back)
    
    # Skip the state if there's not enough data
    if X.size == 0 or Y.size == 0:
        print(f"Not enough data to train for state: {state}. Skipping...")
        continue
    
    # Reshape input to be [samples, time steps, features]
    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))
    
    # Split the dataset into training and testing sets
    trainX, _, trainY, _ = train_test_split(X, Y, test_size=0.33, random_state=42)
    
    # Build the LSTM model
    model_lstm = Sequential([
        LSTM(lstm_units, input_shape=(1, look_back), return_sequences=False),
        Dense(1)
    ])
    model_lstm.compile(optimizer='adam', loss='mean_squared_error')
    
    # Train the LSTM model
    model_lstm.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=2)
    
    # Save the model
    model_lstm.save(f'models/lstm_model_petroleum_sales_{state}.h5')
    print(f"LSTM model saved for state: {state}")

    # Evaluate the model on the test set
    print(f"Evaluating LSTM model for state: {state}")
    
    # Predict on the test set
    predictions = model_lstm.predict(trainX)
    
    # Inverse transform the predictions and the actual values
    predictions = scaler.inverse_transform(predictions)
    trainY = scaler.inverse_transform(trainY.reshape(-1, 1))
    
    # Calculate performance metrics
    mse = mean_squared_error(trainY, predictions)
    mape = mean_absolute_percentage_error(trainY, predictions)
    
    print(f"State: {state} - MSE: {mse}, MAPE: {mape}")
