import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense
import os
import tensorflow as tf

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Load your data (update path accordingly)
data = pd.read_csv('/content/final_training_file.csv')  # Update this path to your file location
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# Get a list of all unique states
states = data['State'].unique()

# Create a directory to save the models
if not os.path.exists('models'):
    os.makedirs('models')

# Function to create a dataset with look-back sequences
def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        X.append(dataset[i:(i + look_back), 0])
        Y.append(dataset[i + look_back, 0])  # EV_Stations column
    return np.array(X), np.array(Y)

# Define the look-back period
look_back = 6  # Can be tuned for different results

# Loop through each state and train the model
for state in states:
    print(f"Training model for state: {state}")
    
    # Extract data for the current state
    ev_stations = data[data['State'].str.lower() == state.lower()]['EV_Stations'].values.reshape(-1, 1)
    
    # Normalize the features
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_values = scaler.fit_transform(ev_stations)
    
    # Create datasets
    X, Y = create_dataset(scaled_values, look_back)
    
    # Skip the state if there's not enough data
    if X.size == 0 or Y.size == 0:
        print(f"Not enough data to train for state: {state}. Skipping...")
        continue
    
    # Reshape input to be [samples, time steps, features]
    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))
    
    # Split the dataset into training and testing sets
    trainX, _, trainY, _ = train_test_split(X, Y, test_size=0.33, random_state=42)
    
    # Build the SimpleRNN model
    model_rnn = Sequential([
        SimpleRNN(50, input_shape=(1, look_back), return_sequences=False),
        Dense(1)
    ])
    model_rnn.compile(optimizer='adam', loss='mean_squared_error')
    
    # Train the SimpleRNN model
    model_rnn.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)
    
    # Save the model
    model_rnn.save(f'models/simplernn_model_{state}.h5')
    print(f"Model saved for state: {state}")

# Define the look-back period (should match the look-back used during training)
look_back = 6

# Initialize a list to store future predictions
future_predictions = []

# Loop through each state and load the model for predictions
for state in states:
    print(f"Predicting for state: {state}")
    
    # Load the trained model
    model_path = f'/content/models/simplernn_model_{state}.h5'
    if not os.path.exists(model_path):
        print(f"No model found for state: {state}. Skipping...")
        continue
    
    model_rnn = load_model(model_path)
    
    # Extract data for the current state
    ev_stations = data[data['State'].str.lower() == state.lower()]['EV_Stations'].values.reshape(-1, 1)
    
    # Normalize the features using the same scaler
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_values = scaler.fit_transform(ev_stations)
    
    # Predict future values (Jan 2025 - Dec 2026) only if there is enough data
    if len(scaled_values) >= look_back:
        future_input = scaled_values[-look_back:].reshape(1, 1, look_back)  # Adjust shape to match RNN input
        future_state_predictions = []
        last_value = scaled_values[-1, 0]  # Initialize with the last value from the actual data
        
        for month in pd.date_range(start='2025-01-01', end='2026-12-01', freq='MS'):
            future_prediction = model_rnn.predict(future_input)
            predicted_value = future_prediction[0, 0]
            
            # Ensure the prediction is at least 0.01 higher than the last value
            if predicted_value <= last_value:
                predicted_value = last_value + 0.01
            
            future_state_predictions.append(predicted_value)
            last_value = predicted_value  # Update the last_value
            
            # Reshape predicted_value to (1, 1, 1) before appending
            predicted_value_reshaped = np.array(predicted_value).reshape(1, 1, 1)
            
            # Update the input for the next prediction by appending the predicted value
            future_input = np.append(future_input[:, :, 1:], predicted_value_reshaped, axis=2)
        
        # Inverse transform and store the predictions
        future_state_predictions = scaler.inverse_transform(np.array(future_state_predictions).reshape(-1, 1)).flatten()
        for i, value in enumerate(future_state_predictions):
            future_predictions.append({'State': state, 'Date': pd.date_range(start='2025-01-01', periods=24, freq='MS')[i], 'Predicted_EV_Stations': value})

# Convert future predictions to a DataFrame and save
future_predictions_df = pd.DataFrame(future_predictions)
future_predictions_df.to_csv('predictions/future_predictions_2025_2026.csv', index=False)

# Optional: Print a summary of future predictions
print("\nFuture Predictions Summary:")
print(future_predictions_df.head())

